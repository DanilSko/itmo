{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как использовать этот код \n",
    "### (можно пропустить эту часть, если вы знаете, что такое Jupyter и ipynb-тетрадки -- в таком случае переходите сразу к \"Начало работы\")\n",
    "Перед вами тетрадка Jupyter Notebook. Это одна из популярных сред для написания и __демонстрации__ кода на Python (и не только). Jupyter запускает питоновский код прямо в браузере (но локально, т.е. код исполняет ваш компьютер, в отличие от, например Google Colab). В Jupyter код можно запускать не целиком, а по ячейкам. Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы с Даней сегодня позапускаем морфоанализаторы\n"
     ]
    }
   ],
   "source": [
    "# ячейка с кодом\n",
    "text = 'Мы с Даней сегодня позапускаем морфоанализаторы'\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МЫ С ДАНЕЙ СЕГОДНЯ ПОЗАПУСКАЕМ МОРФОАНАЛИЗАТОРЫ\n"
     ]
    }
   ],
   "source": [
    "# еще одна ячейка с кодом. \n",
    "# Пространство имен общее — переменная text была заполнена в предыдущей ячейке\n",
    "print (text.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, ячейки бывают текстовыми — их можно форматировать с помощью формата разметки markdown (.md). Текст, который вы сейчас читаете, написан как раз в таком формате. Файлы Jupyter Notebook имеют расширение .ipynb и автоматически рендерятся гитхабом. Например, эта же __[тетрадка](https://github.com/DanilSko/itmo/blob/master/ITMO_practice/BasicProcessing/Basic%20text%20processing%20Danya%20ITMO.ipynb)__  у меня на гитхабе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Окей, а как я могу запустить код в таком .ipynb?\n",
    "\n",
    "Есть разные варианты: \n",
    "\n",
    "### Через __[Google Colab](https://colab.research.google.com)__. \n",
    "\n",
    "Google Colab — это гугловский инструмент для написания кода в браузере и запуска прямо на серверах Google (с возможностью бесплатно использовать их вычислительные мощности, в т.ч. графические процессор  — GPU).  Google Colab — родственник Jupyter, они очень похожи. Разница в том, что Jupyter работает локально и использует ваш собственный питон, а Google Colab — это облачный сервис, похожий на Google Docs: вы можете делиться тетрадками и т.д. В Colab можно открыть эту тетрадку, указав ссылку на нее: \n",
    "\n",
    "![Colab](pics/github2colab.png) \n",
    "\n",
    "Просто загрузить .ipynb-файл в Colab тоже можно. \n",
    "\n",
    "### Скачать себе .ipynb и открыть в Jupyter\n",
    "\n",
    "Скачать .ipynb с гитхаба: \n",
    "\n",
    "![Raw](pics/raw_download.png) \n",
    "\n",
    "Поставить Jupyter Notebook по инструкции __[отсюда](https://jupyter.readthedocs.io/en/latest/install.html)__. Открыть терминал (в Windows — командную строку).пойти в папку, внутри которой лежит скачанный .ipynb, написать там jupyter notebook. После этого у вас должно открыться в браузере что-то такое:\n",
    "\n",
    "![Colab](pics/jupyter2.png)\n",
    "\n",
    "Тыкайте на тетрадку -- и все, можно работать в ней, писать код и т.п. Из Jupyter можно выгрузить и отдельно код в виде файла .py (но тогда разделение на ячейки пропадет).\n",
    "\n",
    "### Скачать .ipynb и открыть в PyCharm\n",
    "Если вы любите популярную у питонистов IDE PyCharm  -- она умеет открывать ipynb. Но для этого все равно нужен установеленный Jupyter. Поэтому надо проделать все то же, что в предыд.пункте, а потом открыть файл в PyCharm.\n",
    "\n",
    "### (хак) Скачать файл .py из Google Colab или Jupyter и открыть в PyCharm или любой IDE\n",
    "Из Colab после создания копии вы можете выгрузить не весь .ipynb, а только код в .py. Этот код уже можно запускать где угодно, хоть из командной строки (терминала) вашего компьютера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим, что рядом в папке лежит файл с Преступлением и наказанием.\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## У тех, кто смотрит в колабе, его, естественно, не будет. Поэтому вот стандартный код для загрузки в колаб\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __[Ссылка на текстовый файл с Преступлением и наказанием](https://github.com/DanilSko/itmo/blob/master/ITMO_practice/BasicProcessing/Dostoevsky_PrestuplenieINakazanie.txt)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# откроем файл в питоне\n",
    "path_to_file = 'Dostoevsky_PrestuplenieINakazanie.txt'\n",
    "prest_i_nak = open (path_to_file, 'r')\n",
    "prest_i_nak_kak_stroka = prest_i_nak.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094386"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## попробуйте вывести тут длину строки с помощью функции len; надо написать len (prest_i_nak_kak_stroka) -- так вы передадите в функцию len ваш текст, считанный в сторку \n",
    "len (prest_i_nak_kak_stroka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Преступление и наказание \\n\\nРоман в шести частях с эпилогом\\n\\n  \\nЧасть первая\\n\\nI\\n\\n   В начале июля, в '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## попробуйте получить срез из первых 100 символов вашей строки с помощью срезов списка [:]\n",
    "## т.е. напишите ниже вот это: prest_i_nak_kak_stroka [:100]\n",
    "## и нажмите выполнить\n",
    "prest_i_nak_kak_stroka [:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сегментация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Простейший способ сегментации строки на токены (как бы на слова, но тупее грубее) — питоновский встроенный метод .split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prest_i_nak_kak_spisok_slov = prest_i_nak_kak_stroka.split() ## здесь в качестве аргумента можно воткнуть разделитель; по умолчанию это любое количество пробелов\n",
    "#print ('Примерное количество слов в \"Преступлении и наказании\":', len (prest_i_nak_kak_spisok_slov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prest_i_nak_kak_spisok_slov[:200]\n",
    "\n",
    "#type (prest_i_nak_kak_stroka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### попробуем получить список уникальных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prest_i_nak_kak_mnojestvo = set(prest_i_nak_kak_spisok_slov)\n",
    "len (prest_i_nak_kak_mnojestvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prest_i_nak_kak_mnojestvo_slov = set (prest_i_nak_kak_spisok_slov)\n",
    "len (prest_i_nak_kak_mnojestvo_slov)\n",
    "prest_i_nak_kak_spisok_unikalnyh_slov = list (prest_i_nak_kak_mnojestvo_slov)\n",
    "(prest_i_nak_kak_spisok_unikalnyh_slov).sort()\n",
    "prest_i_nak_kak_spisok_unikalnyh_slov [:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Более умный способ: сегментируем текст регекспом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## питоновский модуль для регекспов\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prest_i_nak_spisok_re =  re.split ('( +|[.,!? –]|\\n)',prest_i_nak_kak_stroka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prest_i_nak_spisok_re [:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Еще более умный способ: сегментируем текст готовым токенизатором — возьмем его из прекрасной библиотеки для обработки языка NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если у вас еще нет nltk, установите его:\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "prest_i_nak_nltk_tokenized = word_tokenize (prest_i_nak_kak_stroka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь давайте посчитаем частотность слов в нашем списке слов; т.е. собственно как часто повторяется каждое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 25337),\n",
       " ('.', 8198),\n",
       " ('и', 8021),\n",
       " ('--', 6073),\n",
       " ('не', 3533),\n",
       " ('в', 3515),\n",
       " ('!', 3265),\n",
       " ('что', 3010),\n",
       " ('на', 2304),\n",
       " ('?', 2245),\n",
       " ('он', 2166),\n",
       " ('...', 2097),\n",
       " ('с', 1927),\n",
       " ('я', 1805),\n",
       " ('как', 1496),\n",
       " (';', 1271),\n",
       " ('его', 1170),\n",
       " ('же', 1130),\n",
       " ('а', 1103),\n",
       " ('это', 1099),\n",
       " ('так', 1025),\n",
       " (':', 940),\n",
       " ('всё', 871),\n",
       " ('к', 868),\n",
       " ('бы', 865),\n",
       " ('но', 808),\n",
       " ('вы', 805),\n",
       " ('было', 772),\n",
       " ('``', 741),\n",
       " (\"''\", 739),\n",
       " ('она', 700),\n",
       " ('Он', 686),\n",
       " ('А', 672),\n",
       " ('еще', 664),\n",
       " ('то', 657),\n",
       " ('даже', 641),\n",
       " ('у', 620),\n",
       " ('по', 619),\n",
       " ('за', 611),\n",
       " ('ее', 611),\n",
       " ('Я', 590),\n",
       " ('только', 580),\n",
       " ('Раскольников', 565),\n",
       " ('Да', 537),\n",
       " ('теперь', 530),\n",
       " ('да', 518),\n",
       " ('уже', 518),\n",
       " ('меня', 517),\n",
       " ('вдруг', 514),\n",
       " ('ты', 507),\n",
       " ('от', 487),\n",
       " ('ему', 466),\n",
       " ('быть', 455),\n",
       " ('уж', 446),\n",
       " ('из', 445),\n",
       " ('мне', 438),\n",
       " ('И', 430),\n",
       " ('был', 421),\n",
       " ('вот', 406),\n",
       " ('до', 402),\n",
       " ('вам', 395),\n",
       " ('о', 382),\n",
       " ('себя', 375),\n",
       " ('вас', 373),\n",
       " ('ведь', 370),\n",
       " ('ли', 368),\n",
       " ('него', 365),\n",
       " ('очень', 364),\n",
       " ('Ну', 363),\n",
       " ('..', 349),\n",
       " ('Но', 347),\n",
       " ('опять', 334),\n",
       " ('может', 322),\n",
       " ('была', 297),\n",
       " ('есть', 295),\n",
       " ('если', 293),\n",
       " ('тоже', 291),\n",
       " ('Это', 286),\n",
       " ('сам', 282),\n",
       " ('ни', 279),\n",
       " ('все', 273),\n",
       " ('тут', 272),\n",
       " ('когда', 269),\n",
       " ('потому', 267),\n",
       " ('Соня', 267),\n",
       " ('раз', 266),\n",
       " ('(', 264),\n",
       " (')', 264),\n",
       " ('того', 259),\n",
       " ('их', 247),\n",
       " ('Не', 246),\n",
       " ('или', 246),\n",
       " ('Разумихин', 244),\n",
       " ('тогда', 239),\n",
       " ('ей', 239),\n",
       " ('человек', 238),\n",
       " ('совсем', 238),\n",
       " ('нет', 232),\n",
       " ('чем', 228),\n",
       " ('чтобы', 228)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## для этого мы тоже не станем писать свое решение с нуля, а воспользуемся готовым от NLTK\n",
    "## возьеме токенизированный список — и засунем его в функцию FreqDist от NLTK\n",
    "from nltk import FreqDist\n",
    "word_freqs_prest_i_nak = FreqDist(prest_i_nak_nltk_tokenized)\n",
    "word_freqs_prest_i_nak.most_common (100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стемминг, лемматизация, морфологический анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В том же NLTK есть готовая реализация стеммера для русского языка. Давайте потестируем ее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## стеммер не быстрый, поэтому давайте возьмем первые 1000 слов, а не все\n",
    "first_1000 = prest_i_nak_nltk_tokenized[:1000]\n",
    "## этот стеммер не умеет сам токенизировать -- он работает только с отдельными словами. \n",
    "## Поэтому придется скармливать ему наш список по одному: \n",
    "prest_i_nak_first_1000_stemmed = []\n",
    "for word in first_1000:\n",
    "    prest_i_nak_first_1000_stemmed.append (stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prest_i_nak_first_1000_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyStem\n",
    "\n",
    "__[Mystem](https://tech.yandex.ru/mystem/)__ - это свободно распространяемый морфологический анализатор для русского языка с закрытым исходным кодом. То есть мы можем его бесплатно скачать с сайта и пользоваться им, но не можем посмотреть, что у него внутри и как оно работает.\n",
    "\n",
    "Mystem был придуман одним из создателей Яндекса Ильёй Сегаловичем. Некоторый потомок Mystem'а до сих пор работает внутри большого поисковика Яндекса, анализируя слова при поиске.\n",
    "\n",
    "MyStem значит my stemmer. Как мы с вами уже знаем (см. выше), стемминг -- это разбиение формы на основу и флексию. Программы-стеммеры умеют превращать фразу 'Маша поехала за грибами' в 'Маш поехал за гриб'.  Но на самом деле MyStem не стеммер, а полноценный морфологический АНАЛИЗАТОР. Он может гораздо больше: устанавливать словарную форму слова, определять часть речи и грамматические характеристики (падеж, число, время, род...). В последних версиях Mystem умеет и выбирать из нескольких возможных грамматических разборов один, наиболее верный.\n",
    "\n",
    "У Mystem нет графического оконного интерфейса, запустить его можно только из командной строки. Зато есть обертка для Python — pymystem3.\n",
    "\n",
    "__[Документация к MyStem](https://tech.yandex.ru/mystem/doc/index-docpage/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# эта клетка нужна вам, если у вас не установлен модуль pymystem3. \n",
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## импортируем непосредственно класс \"анализатор MyStem\" из pymystem3\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help (Mystem()) ## всегда полезно почитать хелпы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['даня', ' ', 'тестировать', ' ', 'машинный', ' ', 'морфология', '\\n']\n"
     ]
    }
   ],
   "source": [
    "moi_analizator = Mystem() ## создаем анализатор\n",
    "test = 'Даня тестирует машинную морфологию' ## создаем тестовую строку\n",
    "lemmatized = moi_analizator.lemmatize(test) ## лемматизируем строку с помощью mystem \n",
    "print (lemmatized) ## напечатаем лемматизированную строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prest_i_nak_by_mystem = moi_analizator.lemmatize(prest_i_nak_kak_stroka) ## лемматизируем преступление и наказание с помощью mystem \n",
    "#print  (prest_i_nak_kak_by_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs_prest_i_nak = FreqDist(prest_i_nak_by_mystem)\n",
    "word_freqs_prest_i_nak.most_common (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
